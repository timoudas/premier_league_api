{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nObjective:\\n    *Docs\\n        - Create summary to easily access description for different data-attributes\\n    *Loading\\n        - Create functions that load arbitrairy amount of json-data for the same\\n        type of statistics.\\n        - Create functions to concatinate json-data of different type\\n    *Analysis\\n        - Visualize data-attributes in graphs\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis and data-loading functions\n",
    "\"\"\"\n",
    "Objective:\n",
    "    *Docs\n",
    "        - Create summary to easily access description for different data-attributes\n",
    "    *Loading\n",
    "        - Create functions that load arbitrairy amount of json-data for the same\n",
    "        type of statistics.\n",
    "        - Create functions to concatinate json-data of different type\n",
    "    *Analysis\n",
    "        - Visualize data-attributes in graphs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directory import Directory\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from functools import reduce \n",
    "import mysql.connector\n",
    "dirs = Directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = Directory()\n",
    "\n",
    "\"\"\"\n",
    "Updates .json files with new data from the api if the json exists\n",
    "\n",
    "Looks if fixtureID exists in .json, if it doesn't exist it gets append\n",
    "\"\"\"\n",
    "\n",
    "def deep_get(dictionary, keys, default=None):\n",
    "    \"\"\"Get values of nested keys from dict\n",
    "        Args:\n",
    "            dictionary(dict): Dict with nested keys\n",
    "            keys(dict.keys()): \".\" separated chain of nested keys, ex \"info.player.name\"\n",
    "    \"\"\"\n",
    "    return reduce(lambda d, key: d.get(key, default) if isinstance(d, dict) else default, keys.split(\".\"), dictionary)\n",
    "\n",
    "def load_player_stats(year):\n",
    "    \"\"\"Load player_stats json files into a container\n",
    "        Args:\n",
    "            year(int): year of player_stats json\n",
    "    \"\"\"\n",
    "    file = f'EN_PR_{start_year}_playerstats.json'\n",
    "    stats_file = dirs.load_json(file, '..', 'json', 'params', 'stats')\n",
    "    stats_file.append({'season':start_year})\n",
    "    return stats_file\n",
    "\n",
    "\"\"\"Read stats from ...playerstats.json into Dataframe,\n",
    "can later be used to import data into DataBase\n",
    "\"\"\"\n",
    "\n",
    "def read_playerstats(data):\n",
    "    \"\"\"Read stats from ...playerstats.json into flattened\n",
    "    list of dicts. \n",
    "    \"\"\"\n",
    "    stats_all = []\n",
    "    stats_temp = {}\n",
    "    for d in data:\n",
    "        stats_temp = {}\n",
    "        if 'stats' in d:\n",
    "            stats = d['stats']\n",
    "            for dicts in stats:\n",
    "                stats_temp['id'] = dicts.get('id')\n",
    "                if dicts.get('name') != None:\n",
    "                    stats_temp[dicts.get('name')] = dicts.get('value')\n",
    "            stats_all.append(stats_temp)\n",
    "    return stats_all\n",
    "\n",
    "def read_playerinfo(data):\n",
    "    \"\"\"Read info from ...playerstats.json into flattened\n",
    "    list of dicts. \n",
    "    \"\"\"\n",
    "    info_all = []\n",
    "    stats_temp = {}\n",
    "    for d in data:\n",
    "        try:\n",
    "            if 'info' in d:\n",
    "                stats = d['info']\n",
    "                stats_temp['age'] = stats.get('age')\n",
    "                stats_temp['id'] = stats.get('id')\n",
    "                stats_temp['birth'] = deep_get(stats, 'birth.date.label')\n",
    "                stats_temp['birth_exact'] = deep_get(stats, 'birth.date.millis')\n",
    "                stats_temp['country'] = deep_get(stats, 'birth.country.country')\n",
    "                stats_temp['isoCode'] = deep_get(stats, 'birth.country.isoCode')\n",
    "                stats_temp['loan'] = deep_get(stats, 'info.loan')\n",
    "                stats_temp['position'] = deep_get(stats, 'info.position')\n",
    "                stats_temp['positionInfo'] = deep_get(stats, 'info.positionInfo')\n",
    "                stats_temp['shirtNum'] = deep_get(stats, 'info.shirtNum')\n",
    "                stats_temp['name'] = deep_get(stats, 'name.display')\n",
    "                stats_temp['first'] = deep_get(stats, 'name.first')\n",
    "                stats_temp['last'] = deep_get(stats, 'name.last')\n",
    "                stats_temp['nationalTeam'] = deep_get(stats, 'nationalTeam.country')\n",
    "                stats_temp['playerId'] = stats.get('playerId')\n",
    "            stats_temp['season'] = d.get('season')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        info_all.append(stats_temp)\n",
    "    return info_all\n",
    "               \n",
    "            \n",
    "start_year = 2017\n",
    "end_year = 2020\n",
    "df = pd.DataFrame()\n",
    "data = []\n",
    "for i in range(start_year, end_year):\n",
    "    data_sample = load_player_stats(i)\n",
    "    stats = read_playerstats(data_sample)\n",
    "    info = read_playerinfo(data_sample)\n",
    "    df1 = pd.DataFrame(stats)\n",
    "    df2 = pd.DataFrame(info)\n",
    "    df3 = pd.merge(info, stats, on='id', how='outer')\n",
    "    df = df.append(df3, ignore_index=True)\n",
    "df.to_csv('player_stats.csv', encoding='utf-8')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "connection = create_connection(\"test_db.sqlite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
