def get_team_links():
    clubs_url = 'https://www.premierleague.com/clubs'
    parent_url = clubs_url.rsplit('/', 1)[0]
    data = requests.get(clubs_url).text
    html = soup(data, 'html.parser')

    team_name = []
    team_link = []

    for ul in html.find_all('ul', {'class': 'block-list-5 block-list-3-m block-list-1-s block-list-1-xs block-list-padding dataContainer'}):
        for a in ul.find_all('a'):
            team_name.append(str(a.h4).split('>', 1)[1].split('<')[0])
            team_link.append(parent_url+a['href'])
    team_link = [item.replace('overview', 'squad') for item in team_link]
    team = dict(zip(team_name, team_link))
return team


def get_player_info()
    players = {}
    for team_name, team_link in team.items():
        players[team_name] = []
        player_page = requests.get(team_link)
        cont = soup(player_page.content, 'lxml')
        clud_ele = cont.find_all('span', attrs={'class' : 'playerCardInfo'})
        for player_info in clud_ele:
            number = player_info.select('span.number')[0].get_text(strip=True)
            if number == '-':
                number = 100
            name = player_info.select('h4.name')[0].get_text(strip=True)
            position = player_info.select('span.position')[0].get_text(strip=True)
            players[team_name].append({'name': name,
                               'position': position,
                               'number': number})
    return players
